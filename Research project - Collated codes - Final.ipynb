{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgbm\n",
    "from seaborn import *\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_reg = pd.DataFrame(columns = ['accuracy_linear', 'accuracy_lin_rf_ensemble', 'accuracy_lin_rf_gbm_ensemble', \n",
    "                                'accuracy_lin_rf_gbm_xgb_ensemble', 'accuracy_lin_rf_gbm_xgb_lgbm_ensemble', 'num_rows',\n",
    "                                'num_cols'])\n",
    "\n",
    "ensemble_dataset_clf = pd.DataFrame(columns = ['accuracy_logistic', 'accuracy_log_rf_ensemble', 'accuracy_log_rf_gbm_ensemble', \n",
    "                                'accuracy_log_rf_gbm_xgb_ensemble', 'accuracy_log_rf_gbm_xgb_lgbm_ensemble', 'num_rows',\n",
    "                                'num_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "x = glob.glob(r'C:\\Users\\rohit\\Desktop\\MSc. Computer Science - Data Science\\Machine Learning\\Group project\\datasets\\regression\\*.csv')\n",
    "y = glob.glob(r'C:\\Users\\rohit\\Desktop\\MSc. Computer Science - Data Science\\Machine Learning\\Group project\\datasets\\classification\\*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\rohit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\rohit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(x)):\n",
    "    dataset = pd.read_csv(x[i])\n",
    "    \n",
    "    #Dropping all NA rows\n",
    "    dataset= dataset.dropna()\n",
    "\n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(dataset.iloc[:,-1])\n",
    "    \n",
    "    # Remove the labels from the features, axis 1 refers to the columns\n",
    "    dataset= dataset.iloc[:, :-1]\n",
    "    \n",
    "    #One hot encoding\n",
    "    dataset1 = pd.get_dummies(dataset)\n",
    "    \n",
    "    # Saving feature names for later use\n",
    "    dataset1_list = list(dataset1.columns)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    dataset1 = np.array(dataset1)\n",
    "    \n",
    "    # Using Skicit-learn to split data into training and testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    train_dataset1, test_dataset1, train_labels, test_labels = train_test_split(dataset1, labels, \n",
    "                                                                                test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    #LinearRegression\n",
    "    linear_reg = LinearRegression().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_linear = linear_reg.predict(test_dataset1)\n",
    "    pred_linear\n",
    "\n",
    "    #Accuracy of linear regression model\n",
    "    accuracy_linear = r2_score(test_labels, pred_linear)\n",
    "    accuracy_linear\n",
    "\n",
    "    #RandomForest\n",
    "    rf_reg = RandomForestRegressor(n_estimators = 1000, random_state = 1).fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_rf = rf_reg.predict(test_dataset1)\n",
    "    pred_rf\n",
    "\n",
    "    #Accuracy of rf model\n",
    "    accuracy_rf = r2_score(test_labels, pred_rf)\n",
    "    accuracy_rf\n",
    "\n",
    "    #ensembled predictions \n",
    "    pred = (pred_rf + pred_linear)/2\n",
    "\n",
    "    #Accuracy of ensembled model\n",
    "    accuracy_lin_rf_ensemble = r2_score(test_labels, pred)\n",
    "    accuracy_lin_rf_ensemble\n",
    "\n",
    "    #Gradient Boosting\n",
    "    GBM_reg = GradientBoostingRegressor().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_gbm = GBM_reg.predict(test_dataset1)\n",
    "    pred_gbm\n",
    "\n",
    "    #Accuracy of gbm model\n",
    "    accuracy_gbm = r2_score(test_labels, pred_gbm)\n",
    "    accuracy_gbm\n",
    "\n",
    "    #ensembled predictions for linear, rf, gbm\n",
    "    pred = (pred_rf + pred_linear + pred_gbm)/3\n",
    "\n",
    "    #Accuracy of ensembled model\n",
    "    accuracy_lin_rf_gbm_ensemble = r2_score(test_labels, pred)\n",
    "    accuracy_lin_rf_gbm_ensemble\n",
    "\n",
    "    #Xtreme Gradient Boosting\n",
    "    XGB_reg = XGBRegressor().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_xgb = XGB_reg.predict(test_dataset1)\n",
    "    pred_xgb\n",
    "\n",
    "    #Accuracy of xgb model\n",
    "    accuracy_xgb = r2_score(test_labels, pred_xgb)\n",
    "    accuracy_xgb\n",
    "\n",
    "    #ensembled predictions for linear, rf, gbm,xgb\n",
    "    pred = (pred_rf + pred_linear + pred_gbm + pred_xgb)/4\n",
    "\n",
    "    #Accuracy of ensembled model\n",
    "    accuracy_lin_rf_gbm_xgb_ensemble = r2_score(test_labels, pred)\n",
    "    accuracy_lin_rf_gbm_xgb_ensemble\n",
    "\n",
    "    #Light Gradient Boosting\n",
    "    LGBM_reg = lgbm.LGBMRegressor().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_lgbm = LGBM_reg.predict(test_dataset1)\n",
    "    pred_lgbm\n",
    "\n",
    "    #Accuracy of lgbm model\n",
    "    accuracy_lgbm = r2_score(test_labels, pred_lgbm)\n",
    "    accuracy_lgbm\n",
    "\n",
    "    #ensembled predictions for linear, rf, gbm, xgb, lgbm\n",
    "    pred = (pred_rf + pred_linear + pred_gbm + pred_xgb + pred_lgbm)/5\n",
    "\n",
    "    #Accuracy of ensembled model\n",
    "    accuracy_lin_rf_gbm_xgb_lgbm_ensemble = r2_score(test_labels, pred)\n",
    "    accuracy_lin_rf_gbm_xgb_lgbm_ensemble\n",
    "    \n",
    "    ensemble_dataset_reg = ensemble_dataset_reg.append({'accuracy_linear' :accuracy_linear, \n",
    "                                            'accuracy_lin_rf_ensemble': accuracy_lin_rf_ensemble, \n",
    "                                            'accuracy_lin_rf_gbm_ensemble':accuracy_lin_rf_gbm_ensemble, \n",
    "                                            'accuracy_lin_rf_gbm_xgb_ensemble':accuracy_lin_rf_gbm_xgb_ensemble,\n",
    "                                            'accuracy_lin_rf_gbm_xgb_lgbm_ensemble':accuracy_lin_rf_gbm_xgb_lgbm_ensemble, \n",
    "                                            'num_rows': len(train_dataset1),\n",
    "                                            'num_cols': len((dataset1[0]))},\n",
    "                                             ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(0,len(y)):\n",
    "    dataset = pd.read_csv(y[i])\n",
    "\n",
    "    #Dropping all NA rows\n",
    "    dataset= dataset.dropna()\n",
    "\n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(dataset.iloc[:,-1])\n",
    "\n",
    "    # Remove the labels from the features, axis 1 refers to the columns\n",
    "    dataset= dataset.iloc[:, :-1]\n",
    "\n",
    "    #One hot encoding\n",
    "    dataset1 = pd.get_dummies(dataset)\n",
    "\n",
    "    # Saving feature names for later use\n",
    "    dataset1_list = list(dataset1.columns)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    dataset1 = np.array(dataset1)\n",
    "\n",
    "    # Using Skicit-learn to split data into training and testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_dataset1, test_dataset1, train_labels, test_labels = train_test_split(dataset1, labels, \n",
    "                                                                                test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    \n",
    "    #LogisticRegression\n",
    "    logistic_reg = LogisticRegression().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_log = logistic_reg.predict(test_dataset1)\n",
    "\n",
    "    #Accuracy of Logistic regression model\n",
    "    accuracy_log = sklearn.metrics.accuracy_score(test_labels, pred_log, normalize=True, sample_weight=None)\n",
    "    \n",
    "    #RandomForest\n",
    "    rf_clf = RandomForestClassifier(n_estimators = 1000, random_state = 1).fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_rf = rf_clf.predict(test_dataset1)\n",
    "\n",
    "    #Accuracy of rf model\n",
    "    accuracy_rf = sklearn.metrics.accuracy_score(test_labels, pred_rf, normalize=True, sample_weight=None)\n",
    "    \n",
    "    \n",
    "    #Accuracy of ensemble model of Logistic and RandomForest\n",
    "    model = VotingClassifier(estimators=[('lr', logistic_reg), ('rf', rf_clf)], voting='hard')\n",
    "    model.fit(train_dataset1,train_labels)\n",
    "    accuracy_log_rf_ensemble = model.score(test_dataset1,test_labels)\n",
    "    \n",
    "\n",
    "    #Gradient Boosting\n",
    "    GBM_clf = GradientBoostingClassifier().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_gbm = GBM_clf.predict(test_dataset1)\n",
    "\n",
    "    #Accuracy of gbm model\n",
    "    accuracy_gbm = sklearn.metrics.accuracy_score(test_labels, pred_gbm, normalize=True, sample_weight=None)\n",
    "    \n",
    "    \n",
    "    #Accuracy of ensemble model of Logistic , RandomForest and GBM\n",
    "    model = VotingClassifier(estimators=[('lr', logistic_reg), ('rf', rf_clf) , ('gbm', GBM_clf)], voting='hard')\n",
    "    model.fit(train_dataset1,train_labels)\n",
    "    accuracy_log_rf_gbm_ensemble = model.score(test_dataset1,test_labels)\n",
    "\n",
    "\n",
    "    #Xtreme Gradient Boosting\n",
    "    XGB_clf = XGBClassifier().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_xgb = XGB_clf.predict(test_dataset1)\n",
    "\n",
    "    #Accuracy of xgb model\n",
    "    accuracy_xgb = sklearn.metrics.accuracy_score(test_labels, pred_xgb, normalize=True, sample_weight=None)\n",
    "    \n",
    "    \n",
    "    #Accuracy of ensemble model of Logistic , RandomForest , GBM and XGB\n",
    "    model = VotingClassifier(estimators=[('lr', logistic_reg), ('rf', rf_clf), ('gbm', GBM_clf), ('xgb', XGB_clf)], voting='hard')\n",
    "    model.fit(train_dataset1,train_labels)\n",
    "    accuracy_log_rf_gbm_xgb_ensemble = model.score(test_dataset1,test_labels)\n",
    "\n",
    "    \n",
    "    #Light Gradient Boosting\n",
    "    LGBM_clf = lgbm.LGBMClassifier().fit(train_dataset1, train_labels)\n",
    "\n",
    "    pred_lgbm = LGBM_clf.predict(test_dataset1)\n",
    "\n",
    "    #Accuracy of lgbm model\n",
    "    accuracy_lgbm = sklearn.metrics.accuracy_score(test_labels, pred_lgbm, normalize=True, sample_weight=None)\n",
    "\n",
    "    \n",
    "    #Accuracy of ensemble model of Logistic , RandomForest , GBM , XGB and LGBM\n",
    "    model = VotingClassifier(estimators=[('lr', logistic_reg), ('rf', rf_clf) , ('gbm', GBM_clf) , ('xgb', XGB_clf) , ('lgbm', LGBM_clf)], voting='hard')\n",
    "    model.fit(train_dataset1,train_labels)\n",
    "    accuracy_log_rf_gbm_xgb_lgbm_ensemble = model.score(test_dataset1,test_labels)    \n",
    "    \n",
    "    \n",
    "    ensemble_dataset_clf = ensemble_dataset_clf.append({'accuracy_logistic' :accuracy_log, \n",
    "                                            'accuracy_log_rf_ensemble': accuracy_log_rf_ensemble, \n",
    "                                            'accuracy_log_rf_gbm_ensemble':accuracy_log_rf_gbm_ensemble, \n",
    "                                            'accuracy_log_rf_gbm_xgb_ensemble':accuracy_log_rf_gbm_xgb_ensemble,\n",
    "                                            'accuracy_log_rf_gbm_xgb_lgbm_ensemble':accuracy_log_rf_gbm_xgb_lgbm_ensemble, \n",
    "                                            'num_rows': len(train_dataset1),\n",
    "                                            'num_cols': len((dataset1[0]))},\n",
    "                                             ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_clf.to_csv('New_Classification_ensembles.csv')\n",
    "ensemble_dataset_reg.to_csv('New_Regression_ensembles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_clf= pd.read_csv('New_Classification_ensembles.csv')\n",
    "ensemble_dataset_reg= pd.read_csv('New_Regression_ensembles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_reg = ensemble_dataset_reg.iloc[:,1:6]\n",
    "ensemble_dataset_clf = ensemble_dataset_clf.iloc[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_clf_change = pd.DataFrame()\n",
    "ensemble_dataset_clf_change['rf_impact'] = (ensemble_dataset_clf.accuracy_log_rf_ensemble - \n",
    "                                         ensemble_dataset_clf.accuracy_logistic)*100/abs(ensemble_dataset_clf.accuracy_logistic)\n",
    "ensemble_dataset_clf_change['gbm_impact'] = (ensemble_dataset_clf.accuracy_log_rf_gbm_ensemble - \n",
    "                                         ensemble_dataset_clf.accuracy_log_rf_ensemble)*100/abs(ensemble_dataset_clf.accuracy_log_rf_ensemble)\n",
    "ensemble_dataset_clf_change['xgb_impact'] = (ensemble_dataset_clf.accuracy_log_rf_gbm_xgb_ensemble - \n",
    "                                         ensemble_dataset_clf.accuracy_log_rf_gbm_ensemble)*100/abs(ensemble_dataset_clf.accuracy_log_rf_gbm_ensemble)\n",
    "ensemble_dataset_clf_change['lgbm_impact'] = (ensemble_dataset_clf.accuracy_log_rf_gbm_xgb_lgbm_ensemble - \n",
    "                                         ensemble_dataset_clf.accuracy_log_rf_gbm_xgb_ensemble)*100/abs(ensemble_dataset_clf.accuracy_log_rf_gbm_xgb_ensemble)\n",
    "\n",
    "ensemble_dataset_reg_change = pd.DataFrame()\n",
    "ensemble_dataset_reg_change['rf_impact'] = (ensemble_dataset_reg.accuracy_lin_rf_ensemble - \n",
    "                                         ensemble_dataset_reg.accuracy_linear)*100/ abs(ensemble_dataset_reg.accuracy_linear)\n",
    "ensemble_dataset_reg_change['gbm_impact'] = (ensemble_dataset_reg.accuracy_lin_rf_gbm_ensemble - \n",
    "                                         ensemble_dataset_reg.accuracy_lin_rf_ensemble)*100/abs(ensemble_dataset_reg.accuracy_lin_rf_ensemble)\n",
    "ensemble_dataset_reg_change['xgb_impact'] = (ensemble_dataset_reg.accuracy_lin_rf_gbm_xgb_ensemble - \n",
    "                                         ensemble_dataset_reg.accuracy_lin_rf_gbm_ensemble)*100/abs(ensemble_dataset_reg.accuracy_lin_rf_gbm_ensemble)\n",
    "ensemble_dataset_reg_change['lgbm_impact'] = (ensemble_dataset_reg.accuracy_lin_rf_gbm_xgb_lgbm_ensemble - \n",
    "                                         ensemble_dataset_reg.accuracy_lin_rf_gbm_xgb_ensemble)*100/abs(ensemble_dataset_reg.accuracy_lin_rf_gbm_xgb_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_clf_change.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of ensemble model when additional models are added to it\n",
    "Logistic = 100\n",
    "Logistic_RF = Logistic * 1.00390079\n",
    "Logistic_RF_GBM = Logistic_RF * 1.07371730\n",
    "Logistic_RF_GBM_XGB = Logistic_RF_GBM * 1.00204568\n",
    "Logistic_RF_GBM_XGB_LGBM = Logistic_RF_GBM_XGB * 1.00823062\n",
    "Impact = pd.DataFrame([Logistic,Logistic_RF,Logistic_RF_GBM,Logistic_RF_GBM_XGB,Logistic_RF_GBM_XGB_LGBM])\n",
    "Impact['Models'] = ['Logistic', 'RandomForest', 'GradientBoosting', 'XtremeGradientBoosting', 'LightGBM' ]\n",
    "Impact.columns = ['Contribution', 'Models']\n",
    "\n",
    "g = sns.barplot(y=\"Models\", x=\"Contribution\", data=Impact, palette=\"rainbow\")\n",
    "g.set(xlim=(90, None))\n",
    "g.set(xlabel='Percentage increase in Ensemble accuracy over benchmark of Logistic', ylabel='Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_reg_change.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of ensemble model when additional models are added to it\n",
    "Linear = 100\n",
    "Linear_RF = Linear * 1.44256531\n",
    "Linear_RF_GBM = Linear_RF * 1.06970308\n",
    "Linear_RF_GBM_XGB = Linear_RF_GBM * 1.01479953\n",
    "Linear_RF_GBM_XGB_LGBM = Linear_RF_GBM_XGB * 1.01369670\n",
    "Impact = pd.DataFrame([Linear,Linear_RF,Linear_RF_GBM,Linear_RF_GBM_XGB,Linear_RF_GBM_XGB_LGBM])\n",
    "Impact['Models'] = ['Linear', 'RandomForest', 'GradientBoosting', 'XtremeGradientBoosting', 'LightGBM' ]\n",
    "Impact.columns = ['Contribution', 'Models']\n",
    "\n",
    "g = sns.barplot(y=\"Models\", x=\"Contribution\", data=Impact, palette=\"rainbow\")\n",
    "g.set(xlim=(90, None))\n",
    "g.set(xlabel='Percentage increase in Ensemble accuracy over benchmark of Linear', ylabel='Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_reg.loc[0:5].to_csv('xyz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dataset_clf.loc[0:5].to_csv('pqr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_contributions = ensemble_dataset_reg_change.describe()\n",
    "reg_model_contributions = pd.DataFrame(reg_model_contributions.iloc[1])\n",
    "reg_model_contributions['Increment'] = (reg_model_contributions).index\n",
    "x = sns.barplot(y=\"mean\", x=\"Increment\", data=reg_model_contributions)\n",
    "x.set(xlabel='Impact for regression problems', ylabel='Percentage increase in accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_contributions = ensemble_dataset_clf_change.describe()\n",
    "clf_model_contributions = pd.DataFrame(clf_model_contributions.iloc[1])\n",
    "clf_model_contributions['Increment'] = (clf_model_contributions).index\n",
    "y = sns.barplot(y=\"mean\", x=\"Increment\", data=clf_model_contributions)\n",
    "y.set(xlabel='Impact for classification problems', ylabel='Percentage increase in accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
